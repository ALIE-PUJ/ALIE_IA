from langchain_openai import ChatOpenAI
from langchain.agents import initialize_agent
from langchain.agents import AgentType
from langchain.memory import ConversationBufferMemory
from langchain_groq import ChatGroq
from datetime import date
import os
import time
from langchain.agents import tool

# Importar librería propia
from Libraries.MongoDB_SearchLibrary import * # ChromaDB
# from Milvus.MongoDB.MongoDB_SearchLibrary import * # Milvus
from Libraries.Library.DBsearchTests_Library import * # Relational DB

# Set the maximum execution time for the main agent
max_execution_time = 30

# Traductor
# No se usa google translate, pues necesita una version de httpx incompatible con la de langchain
from deep_translator import GoogleTranslator
def translate_to_spanish(query: str) -> str:
    """
    Translate a given query to Spanish, regardless of the original language.

    This function uses the deep_translator library to convert the input query into Spanish. 
    It ensures that the query is translated properly to facilitate consistent processing.

    Parameters:
    query (str): The input query that needs to be translated to Spanish.

    Returns:
    str: The translated query in Spanish.
    """
    translator = GoogleTranslator(source='auto', target='es')
    translated = translator.translate(query)
    return translated

# Herramientas
@tool
def general_query_handler(user_input: str) -> str:
    """
    Handle general queries directed to the conversational agent ALIE.

    This function is designed to respond to common user queries that do not require specific
    information from databases or external tools. It includes responses to questions about
    the agent's identity, purpose, and general academic inquiries. For more specific queries, use the general_query tool.

    Parameters:
    user_input (str): The input query from the user.

    Returns:
    str: The response generated by ALIE for the given input.
    """
    
    # Normalize user input to lowercase for easier matching
    normalized_input = user_input.lower()

    # Define standard responses for general queries
    responses = {
        "who are you": "I am ALIE, an academic assistance agent designed to help resolve inquiries at Javeriana University.",
        "what is your name": "My name is ALIE, which stands for Academic Learning and Information Expert.",
        "what do you do": "I assist with academic inquiries and provide support for students, faculty, and staff at Javeriana University.",
        "how can you help me": "I can help you with a variety of academic-related questions, such as course information, schedules, and general university resources.",
        "tell me about yourself": "I am ALIE, a conversational agent developed to enhance the academic experience at Javeriana University by providing timely and accurate information.",
        "what is javeriana university": "Javeriana University, also known as Pontificia Universidad Javeriana, is a prestigious educational institution located in Colombia, known for its excellence in teaching and research.",
        "what services do you offer": "I offer support in resolving academic inquiries, providing information about courses, schedules, and other university-related matters."
    }

    # Default response if the query doesn't match any predefined general queries
    default_response = "I'm here to help with any academic inquiries you may have. How can I assist you today?"

    # Check if the user input matches any predefined queries
    response = responses.get(normalized_input, default_response)

    return response

@tool
def search_course_information_vectorStore(user_input: str) -> str:
    """
    Search for multiple courses based on a user's query.

    This function queries the course database to find multiple courses that match the user's input and returns all the available information of the courses that match the query.
    Use this tool when prompted about specific course information, such as course codes, names, descriptions, contents, or any other course-related details.
    
    Parameters:
    user_input (str): The input query from the user, which is used to search for courses.

    Returns:
    str: A list of courses that match the user's query, or a message indicating no results were found.
    """
    
    # Define filter_source as Syllabus for course-related queries
    filter_source = {"source": "Syllabus"}

    query = translate_to_spanish(user_input) # Translate the user input to Spanish for better matching
    print("Original query: ", user_input)
    print("Translated query: ", query)

    # Perform search operation in the course database
    # Replace the following with actual query logic
    result = query_vectordb(query, filter_source=filter_source, search_type="Multiple")
    
    return result

@tool
def general_query_vectorStore(user_input: str) -> str:
    """
    Retrieve general information related to academic topics at Javeriana University. It receives a string query and returns a response.

    This tool is designed to handle various queries related to academia by searching a vector database.
    Use it when prompted about scholarships, lines of emphasis, teachers, student support, certifications, counseling, contact, degrees, registration processes,
    applications, validations, approvals, requirements, state exams such as saber pro, career areas, emphasis, study plan, withdrawal of subjects, and more.

    Usalo cuando te preguten sobre bebcas, lineas de enfasis, profesores, acompañamiento estudiantil, cerficiaciones, consejerias, contacto, grados, procesos de inscripcion,
    solicitudes, validaciones, homologaciones, requisitos, examenes de estado como el saber pro, areas de la carrera, enfasis, plan de estudios, retiro de asignaturas, and more.

    Do not use this tool for course-related queries. Use search_course_information_vectorStore for course-related queries.

    Parameters:
    question (str): The academic-related query from the user.

    Returns:
    str: The agent's response to the provided question.
    """
    
    # Define filter_source as None for no filter
    filter_source = None

    query = translate_to_spanish(user_input) # Translate the user input to Spanish for better matching
    print("Original query: ", user_input)
    print("Translated query: ", query)
    
    # Perform search operation or query
    # Replace the following with actual query logic
    result = query_vectordb(query, filter_source=filter_source, search_type="Multiple") # Can be Single or Multiple
    
    return result

from langchain.chains import ConversationalRetrievalChain
@tool("general_query_chain", return_direct=True) # Return the answer directly without further processing
def general_query_chain(question: str) -> str:
    """
    Retrieve general information related to academic topics at Javeriana University. It receives a string query and returns a response.

    This tool is designed to handle various queries related to academia by searching a vector database.
    Use it when prompted about scholarships, lines of emphasis, teachers, student support, certifications, counseling, contact, degrees, registration processes,
    applications, validations, approvals, requirements, state exams such as saber pro, career areas, emphasis, study plan, withdrawal of subjects, and more.

    Usalo cuando te preguten sobre bebcas, lineas de enfasis, profesores, acompañamiento estudiantil, cerficiaciones, consejerias, contacto, grados, procesos de inscripcion,
    solicitudes, validaciones, homologaciones, requisitos, examenes de estado como el saber pro, areas de la carrera, enfasis, plan de estudios, retiro de asignaturas, and more.

    Do not use this tool for course-related queries. Use search_course_information_vectorStore for course-related queries.

    Parameters:
    question (str): The academic-related query from the user.

    Returns:
    str: The agent's response to the provided question.
    """

    # Initialize the model (Groq)
    llm_primary = ChatGroq(
        model="mixtral-8x7b-32768",
        temperature=0,
        max_tokens=None,
        timeout=None,
    )

    # Initialize memory to maintain context
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True
    )

    # Define the retriever (you would replace this with the actual retriever initialization)
    retriever = get_retriever()  # Replace this with the correct retriever initialization

    # Create the ConversationalRetrievalChain
    qa = ConversationalRetrievalChain.from_llm(
        llm=llm_primary,
        retriever=retriever,
        memory=memory
    )

    # Query the agent
    result = qa({"question": question})

    return result['answer']

# Definir los modelos
def create_agents():
    # Definir el modelo principal (Llama)
      
    llm_primary = ChatOpenAI(
        model="lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF",
        temperature=0.9,
        max_tokens=None,
        timeout=None,
        max_retries=2,
        base_url="http://localhost:1234/v1",
        api_key="lm-studio"
    )
    '''
    
    # Definir el modelo alternativo 1 (Groq)
    llm_primary = ChatGroq(
        model="mixtral-8x7b-32768",
        temperature=0,
        max_tokens=None,
        timeout=None,
    )
'''
    # Definir el modelo alternativo 1 (Groq)
    llm_alternative_1 = ChatGroq(
        model="llama-3.1-70b-versatile",
        temperature=0,
        max_tokens=None,
        timeout=None,
    )

    # Definir el modelo alternativo 2 (otro modelo, por ejemplo)
    llm_alternative_2 = ChatGroq(
        model="llama-3.1-70b-versatile",
        temperature=0,
        max_tokens=None,
        timeout=None,
    )

    # Inicializar los agentes
    agent_primary = initialize_agent(
        [search_course_information_vectorStore, general_query_chain,
         get_students_by_name,
     get_course_by_name,
     get_classes_by_course_code,
     get_classes_by_course_name,
     get_class_by_code,
     get_prerequisites_by_course_code,
     get_prerequisites_by_course_name,
     get_class_schedule,
     get_teacher_by_name], 
        llm_primary,
        memory=ConversationBufferMemory(memory_key="chat_history"),
        agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, 
        handle_parsing_errors=True,
        verbose=True,
        max_execution_time=max_execution_time
    )

    agent_alternative_1 = initialize_agent(
        [search_course_information_vectorStore, general_query_chain,
         get_students_by_name,
     get_course_by_name,
     get_classes_by_course_code,
     get_classes_by_course_name,
     get_class_by_code,
     get_prerequisites_by_course_code,
     get_prerequisites_by_course_name,
     get_class_schedule,
     get_teacher_by_name], 
        llm_alternative_1,
        memory=ConversationBufferMemory(memory_key="chat_history"),
        agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,
        handle_parsing_errors=True,
        verbose=True,
        max_execution_time=max_execution_time
    )

    agent_alternative_2 = initialize_agent(
        [search_course_information_vectorStore, general_query_chain,
         get_students_by_name,
     get_course_by_name,
     get_classes_by_course_code,
     get_classes_by_course_name,
     get_class_by_code,
     get_prerequisites_by_course_code,
     get_prerequisites_by_course_name,
     get_class_schedule,
     get_teacher_by_name], 
        llm_alternative_2,
        memory=ConversationBufferMemory(memory_key="chat_history"),
        agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,
        handle_parsing_errors=True,
        verbose=True
    )

    return [agent_primary, agent_alternative_1, agent_alternative_2]

# Función para iniciar el contador de tiempo
def start_timer():
    return time.time()

# Función para detener el contador de tiempo y calcular la duración
def stop_timer(start_time):
    elapsed_time = time.time() - start_time
    print(f"\nExecution time: {elapsed_time:.2f} seconds")
    return elapsed_time

# Función para ejecutar el agente hasta obtener un resultado satisfactorio de Conversation
def execute_agent_until_success(question):
    agents_with_priority = create_agents()
    
    def try_agent(agent, agent_number, fallback_agents, attempt=1):
        print(f"[DEBUG] ----> Using agent: {agent_number}, Attempt: {attempt}")

        start_time = start_timer()  # Iniciar el contador de tiempo
        
        while True:
            try:
                # Ejecutar el agente con la pregunta proporcionada
                output = agent.run(
                    input=(
                        "[System] You are ALIE, an academic assistance agent designed to help resolve inquiries at Javeriana University. Use tools to retrieve information from databases and external sources, or just answer without the use of tools if the user just wants to interact with you. Answer as quick as possible, but with high quality and as much detail as needed, as links or sources if they can be useful."
                        " [User] " + question
                    )
                )

                # Imprimir el resultado
                print("Answer: ", output)

                # Verificar si el resultado es exitoso
                if "Error:" not in output and "Agent stopped due to iteration limit or time limit" not in output:
                    print("Conversation complete and successful.")
                    stop_timer(start_time)  # Detener el contador de tiempo y mostrar la duración
                    return output  # Devolver el resultado exitoso

                elif "Agent stopped due to iteration limit or time limit" in output:
                    # Si la respuesta es debido a límite de iteración o tiempo, seguir intentando con el siguiente agente
                    print("Conversation: Agent stopped due to iteration limit or time limit. Trying next agent...")
                    raise Exception("Agent stopped due to iteration limit or time limit.")  # Forzar el cambio de agente

            except Exception as e:
                elapsed_time = time.time() - start_time
                if elapsed_time >= max_execution_time:  # Tiempo máximo de ejecución (en segundos) para el agente principal
                    if attempt >= 5 and agent_number == 2:
                        print("Conversation:Failed. Conversation task not completed. Priority level 2 reached and failed.")
                        stop_timer(start_time)  # Detener el contador de tiempo y mostrar la duración
                        return "Conversation:Failed. Conversation task not completed. Priority level 2 reached and failed."
                    else:
                        print(f"\n[AGENT CHANGE] ----> Agent timed out after {elapsed_time:.2f} seconds with a max execution time of {max_execution_time} second(s). Switching to the next agent in the priority list.")
                        if fallback_agents:
                            next_agent = fallback_agents.pop(0)
                            return try_agent(next_agent, agent_number + 1, fallback_agents, attempt + 1)
                        else:
                            # Si llegamos al último agente, continuar intentando con él
                            print(f"[DEBUG] ----> Reached priority level 2. Ending with agent: {agent_number}")
                            stop_timer(start_time)  # Detener el contador de tiempo y mostrar la duración
                            return "Conversation:Failed. Conversation task not completed. Priority level 2 reached and failed."
                print(f"An error occurred: {e}. Trying again...")  # Evitar que el agente explote

    # Iniciar la ejecución con el primer agente y cambiar en caso de error
    return try_agent(agents_with_priority.pop(0), 0, agents_with_priority)


# Ejemplos de traduccion
'''
original_query = "What is the course code for Data Structures?"
translated_query = translate_to_spanish(original_query) # Translate the user input to Spanish for better matching
print("Original query: ", original_query)
print("Translated query: ", translated_query)
'''

# Ejemplo de uso
questions = [
    "Hablame sobre las becas disponibles en la universidad.",
]

# Procesar cada pregunta con el sistema
'''
for question in questions:
    print(f"\nProcessing question: {question}")
    final_answer = execute_agent_until_success(question)
    print("<---- Final answer: ", final_answer)
    input("\nPress Enter to continue...")
'''

question1 = "Is there any student called Luis? Who?"
question2 = "Which is the course code for the course named 'Estructuras de datos'?" # Hay que remover las tildes de las inserciones SQL.
question3 = "Which are the available classes for the course with code 4196?"
question4 = "Which are the available classes for the Estructuras de datos course? Give me their codes"
question5 = "Which are the prerequisites for Estructuras de datos?"
question6 = "Which are the prerequisites for the course with code 4196?"
question7 = "Which are the available schedules for class 1557?"
question8 = "Are there any teachers called Oscar? Who?"
question9 = "Hay algun estudiante llamado Luis? Quien?"
question10 = "Cual es el codigo de la materia llamada 'Estructuras de datos'?"
question11 = "Cuales son las clases disponibles para la materia con codigo 4196?"
question12 = "Cuales son las clases disponibles para la materia Estructuras de datos? Dame sus codigos"
question13 = "Cuales son los prerrequisitos para Estructuras de datos?"
question14 = "Cuales son los prerrequisitos para la materia con codigo 4196?"
question15 = "Cuales son los horarios disponibles para la clase 1557?"
question16 = "Hay algun profesor llamado Oscar? Quien?"
question17 = "What are the expected learning outcomes of estructuras de datos?"
question18 = "Cuales son los resultados de aprendizaje esperados de estructuras de datos?"
question19 = "What scholarships are available for students?"
question20 = "Cuales becas estan disponibles para los estudiantes?"
question21 = "Which are the carrer emphasis for systems engineering?"
question22 = "Cuales son las enfasis de carrera para ingenieria de sistemas?"
question23 = "Which are the available student seedbeds?"
question24 = "Cuales son los semilleros disponibles?"
question25 = "What is ALIE?"

selected_question = question25

print(f"\nProcessing question: {selected_question}")
final_answer = execute_agent_until_success(selected_question)
print("<---- Final answer: ", final_answer)


# Importante. El RAG parece no funcionar muy bien con modelos locales. Es mejor realizarlo con modelos hosteados en la nube.
# El tiempo de respuesta para preguntas RAG es alto. Especificamente en la busqueda de informacion de cursos.